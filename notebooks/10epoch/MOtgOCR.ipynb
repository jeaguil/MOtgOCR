{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT1qOtCluD_V"
      },
      "source": [
        "## MOtgOCR Colab\n",
        "Training custom model with public dataset of representative license plates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMJlUrDluABo",
        "outputId": "1de4decc-5952-4f9e-d5aa-30ad75778c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12187, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 12187 (delta 30), reused 23 (delta 5), pack-reused 12124\u001b[K\n",
            "Receiving objects: 100% (12187/12187), 12.63 MiB | 26.67 MiB/s, done.\n",
            "Resolving deltas: 100% (8380/8380), done.\n",
            "/content/yolov5\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.6 MB 5.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 145 kB 4.9 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 178 kB 39.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 29.1 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 4.7 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54 kB 2.2 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 138 kB 57.1 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62 kB 1.2 MB/s \n",
            "\u001b[?25h  Building wheel for roboflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in License-Plates-1 to yolov5pytorch: 100% [24628423 / 24628423] bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Dataset Version Zip to License-Plates-1 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1689/1689 [00:01<00:00, 1099.56it/s]\n"
          ]
        }
      ],
      "source": [
        "# cloning yolov5\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"\")\n",
        "project = rf.workspace().project(\"license-plates-us-eu-noufs\")\n",
        "dataset = project.version(1).download(\"yolov5\")\n",
        "\n",
        "os.environ[\"DATASET_DIRECTORY\"] = \"/contents/datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NfyhbT4vZri",
        "outputId": "91ee53b2-8cb9-4304-d81d-f4fe35cd991b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/License-Plates-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=8, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v6.2-94-g1aea74c Python-3.7.13 torch-1.12.1+cu113 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs in Weights & Biases\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 17.8MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 95.8MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 270 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5/License-Plates-1/train/labels' images and labels...734 found, 0 missing, 0 empty, 0 corrupt: 100% 734/734 [00:00<00:00, 1350.17it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/License-Plates-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB ram): 100% 734/734 [00:02<00:00, 338.75it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/License-Plates-1/valid/labels' images and labels...70 found, 0 missing, 0 empty, 0 corrupt: 100% 70/70 [00:00<00:00, 645.61it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/License-Plates-1/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 70/70 [00:00<00:00, 248.43it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.22 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9         0G      0.103    0.03256    0.02354         21        416: 100% 92/92 [06:49<00:00,  4.45s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95:   0% 0/5 [00:00<?, ?it/s]WARNING: NMS time limit 0.780s exceeded\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95:  20% 1/5 [00:04<00:16,  4.22s/it]WARNING: NMS time limit 0.780s exceeded\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95:  40% 2/5 [00:08<00:12,  4.21s/it]WARNING: NMS time limit 0.780s exceeded\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95:  60% 3/5 [00:12<00:08,  4.20s/it]WARNING: NMS time limit 0.780s exceeded\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:18<00:00,  3.68s/it]\n",
            "                   all         70        218      0.744      0.231      0.213      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9         0G    0.07824    0.03557    0.01127         32        416: 100% 92/92 [06:41<00:00,  4.36s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:16<00:00,  3.23s/it]\n",
            "                   all         70        218      0.355      0.508       0.33      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9         0G    0.06941    0.03049   0.006391         24        416: 100% 92/92 [06:39<00:00,  4.34s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:15<00:00,  3.06s/it]\n",
            "                   all         70        218       0.55      0.553      0.584      0.289\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9         0G    0.06148    0.03017   0.005225         29        416: 100% 92/92 [06:42<00:00,  4.38s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:15<00:00,  3.07s/it]\n",
            "                   all         70        218      0.583      0.531      0.593       0.24\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9         0G    0.05512    0.02817   0.004618         56        416: 100% 92/92 [06:43<00:00,  4.38s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:15<00:00,  3.01s/it]\n",
            "                   all         70        218      0.618      0.666      0.666      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9         0G    0.04879    0.02819    0.00359         38        416: 100% 92/92 [06:39<00:00,  4.35s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:14<00:00,  2.98s/it]\n",
            "                   all         70        218      0.645      0.743      0.682      0.411\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9         0G    0.04548    0.02638   0.003639         42        416: 100% 92/92 [06:42<00:00,  4.38s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:14<00:00,  2.99s/it]\n",
            "                   all         70        218      0.747      0.765      0.802      0.448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9         0G    0.04088    0.02607   0.003066         24        416: 100% 92/92 [06:43<00:00,  4.39s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:14<00:00,  2.96s/it]\n",
            "                   all         70        218      0.809      0.762      0.809      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9         0G    0.03851    0.02616   0.003136         24        416: 100% 92/92 [06:48<00:00,  4.44s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:15<00:00,  3.02s/it]\n",
            "                   all         70        218      0.816      0.818      0.836      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9         0G     0.0355    0.02457   0.002761         40        416: 100% 92/92 [06:50<00:00,  4.47s/it]\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:14<00:00,  2.99s/it]\n",
            "                   all         70        218      0.825      0.826      0.844      0.576\n",
            "\n",
            "10 epochs completed in 1.168 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 5/5 [00:15<00:00,  3.18s/it]\n",
            "                   all         70        218      0.825      0.826      0.844      0.576\n",
            "         license-plate         70         84      0.829      0.868      0.859      0.546\n",
            "               vehicle         70        134      0.821      0.785      0.829      0.607\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python train.py --img 416 --batch 8 --epochs 10 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "c7Fg_kN-xYO2",
        "outputId": "fd93e00c-ec5b-4b0e-9e36-a32fb173f8fe"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_ae082d34-a698-430b-ac64-58a56aa26c0f\", \"best.pt\", 14340725)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('./runs/train/exp/weights/best.pt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
